{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088098\n",
      "the -> the\n",
      "project -> project\n",
      "gutenberg -> gutenberg\n",
      "ebook -> ebook\n",
      "of -> of\n",
      "the -> the\n",
      "of -> of\n",
      "sherlock -> sherlock\n",
      "holmes -> holmes\n",
      "by -> by\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def only_lowercase_words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "words = only_lowercase_words(open('big.txt').read())\n",
    "MAX_LENGTH_WORD = 10\n",
    "words = [w for w in words if len(w) <= MAX_LENGTH_WORD]\n",
    "print(len(words))\n",
    "\n",
    "\n",
    "words = words[:1000]\n",
    "Xdata = []\n",
    "Ydata = []\n",
    "\n",
    "\n",
    "\n",
    "feature_dict= dict()\n",
    "feature_list = list()\n",
    "\n",
    "PADDING_CHARACTER = '~'\n",
    "feature_dict[PADDING_CHARACTER]=0\n",
    "feature_list.append(PADDING_CHARACTER)\n",
    "max_features = 1\n",
    "\n",
    "def get_vector_from_string(input_s):\n",
    "    global max_features\n",
    "    vector_x = []\n",
    "    for i in input_s:\n",
    "        if i not in feature_dict:\n",
    "            feature_dict[i]=max_features\n",
    "            feature_list.append(i)\n",
    "            max_features += 1\n",
    "        vector_x.append(feature_dict[i])\n",
    "    return vector_x\n",
    "def add_to_data(input_s,output_s):\n",
    "    if len(input_s) < MAX_LENGTH_WORD and len(output_s) < MAX_LENGTH_WORD:\n",
    "        vector_x = get_vector_from_string(input_s)\n",
    "        vector_y = get_vector_from_string(output_s)\n",
    "        Xdata.append(vector_x)\n",
    "        Ydata.append(vector_y)\n",
    "\n",
    "        \n",
    "def print_vector(vector,end_token='\\n'):\n",
    "    print(''.join([feature_list[i] for i in vector]),end=end_token)\n",
    "\n",
    "for line in words:\n",
    "    in_s,out_s = line,line\n",
    "    add_to_data(in_s,out_s)\n",
    "for i in range(10):\n",
    "    print_vector(Xdata[i],end_token='')\n",
    "    print(' -> ', end='')\n",
    "    print_vector(Ydata[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -> after padding: ~~~~~~~the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "before_padding = Xdata[0]\n",
    "Xdata = sequence.pad_sequences(Xdata, maxlen=MAX_LENGTH_WORD)\n",
    "Ydata = sequence.pad_sequences(Ydata, maxlen=MAX_LENGTH_WORD)\n",
    "after_padding  = Xdata[0]\n",
    "\n",
    "print_vector(before_padding,end_token='')\n",
    "print(\" -> after padding: \", end='')\n",
    "print_vector(after_padding)\n",
    "\n",
    "class DataSplitter:\n",
    "    def __init__(self,percentage):\n",
    "        self.percentage = percentage\n",
    "    def split_data(self,data):\n",
    "        splitpoint = int(len(data)*self.percentage)\n",
    "        return data[:splitpoint], data[splitpoint:]\n",
    "splitter = DataSplitter(0.8)\n",
    "Xdata,Xtest = splitter.split_data(Xdata)\n",
    "Ydata,Ytest = splitter.split_data(Ydata)\n",
    "\n",
    "def get_random_reversed_dataset(Xdata,Ydata,batch_size):\n",
    "    newX = []\n",
    "    newY = []\n",
    "    for _ in range(batch_size):\n",
    "        index_taken = random.randint(0,len(Xdata)-1)\n",
    "        newX.append(Xdata[index_taken])\n",
    "        newY.append(Ydata[index_taken][::-1])\n",
    "    return newX,newY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_13:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_14:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_15:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_16:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_17:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_18:0' shape=(?,) dtype=int32>, <tf.Tensor 'Placeholder_19:0' shape=(?,) dtype=int32>]\n",
      "[<tf.Tensor 'ones:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_1:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_2:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_3:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_4:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_5:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_6:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_7:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_8:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'ones_9:0' shape=(64, 26) dtype=float32>]\n",
      "[<tf.Tensor 'add:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_1:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_2:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_3:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_4:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_5:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_6:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_7:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_8:0' shape=(64, 26) dtype=float32>, <tf.Tensor 'add_9:0' shape=(64, 26) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "embedding_dim = 32\n",
    "letters_in_alphabet = 26\n",
    "memory_dim = 248\n",
    "\n",
    "enc_input = [tf.placeholder(tf.int32, shape=(None,)) for i in range(MAX_LENGTH_WORD)]\n",
    "one_hot_input = [tf.one_hot(a, letters_in_alphabet,axis=-1) for a in enc_input]\n",
    "dec_output = [tf.placeholder(tf.int32, shape=(None,)) for t in range(MAX_LENGTH_WORD)]\n",
    "one_hot_dec_output = [tf.one_hot(a, letters_in_alphabet,axis=-1) for a in dec_output]\n",
    "\n",
    "decoder_input = ([tf.zeros_like(one_hot_dec_output[0], dtype=tf.float32)]+[one_hot_dec_output[t] for t in range(MAX_LENGTH_WORD-1)])\n",
    "\n",
    "\n",
    "cell = tf.nn.rnn_cell.GRUCell(memory_dim)\n",
    "\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "output, enc_state = tf.nn.rnn(cell=cell,inputs=one_hot_input,dtype=tf.float32,initial_state=initial_state)\n",
    "\n",
    "softmax_w = tf.Variable(tf.truncated_normal([memory_dim,letters_in_alphabet],stddev=0.5))\n",
    "softmax_b = tf.Variable(tf.truncated_normal([letters_in_alphabet],stddev=0.5))\n",
    "decoder_cell = tf.nn.rnn_cell.GRUCell(memory_dim)\n",
    "\n",
    "\n",
    "def loop(prev, _):\n",
    "    prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "    prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "    return tf.one_hot(prev_symbol,letters_in_alphabet)#tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "\n",
    "\n",
    "strange_weights = tf.Variable(tf.truncated_normal([memory_dim,letters_in_alphabet],stddev=0.5))\n",
    "def stupid_loop_function(prev,some_index):\n",
    "    return prev\n",
    "\n",
    "with tf.variable_scope(\"decoder1\") as scope:\n",
    "    outputs, decoderstate = tf.nn.seq2seq.rnn_decoder(decoder_input, enc_state, decoder_cell)\n",
    "with tf.variable_scope(\"decoder1\",reuse=True) as scope:\n",
    "    testoutputs, teststate = tf.nn.seq2seq.rnn_decoder(decoder_input, enc_state, decoder_cell,loop_function=loop)\n",
    "\n",
    "output_unstacked = tf.unpack(outputs)\n",
    "output_multiplied = [tf.matmul(a,softmax_w) + softmax_b for a in output_unstacked]\n",
    "\n",
    "weights = [tf.ones([batch_size, letters_in_alphabet], dtype=tf.float32) for labels_t in dec_output]\n",
    "\n",
    "print(dec_output)\n",
    "print(weights)\n",
    "print(output_multiplied)\n",
    "difference = [a-b for a in output_multiplied for b in one_hot_dec_output]\n",
    "\n",
    "loss = sum([tf.nn.l2_loss(a) for a in difference])\n",
    "#loss = tf.nn.seq2seq.sequence_loss(output_multiplied, dec_output, weights, letters_in_alphabet)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# Init everything\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29809.4\n",
      "1922.89\n",
      "1819.02\n",
      "1748.89\n",
      "1924.88\n",
      "1809.92\n",
      "1897.82\n",
      "1903.2\n",
      "1839.46\n",
      "1898.41\n",
      "1824.22\n",
      "1806.95\n",
      "1825.8\n",
      "1903.08\n",
      "1887.2\n",
      "1801.6\n",
      "1722.44\n",
      "1886.61\n",
      "1880.75\n",
      "2055.13\n",
      "1791.78\n",
      "1794.29\n",
      "1883.44\n",
      "1848.32\n",
      "1852.56\n",
      "1775.53\n",
      "1861.32\n",
      "1953.35\n",
      "1896.83\n",
      "1788.54\n",
      "1811.82\n",
      "1853.85\n",
      "1838.73\n",
      "1873.38\n",
      "1875.86\n",
      "1872.34\n",
      "1837.89\n",
      "1796.14\n",
      "1840.33\n",
      "1921.85\n",
      "1930.13\n",
      "1804.81\n",
      "2021.81\n",
      "1857.37\n",
      "1885.89\n",
      "1763.71\n",
      "1770.36\n",
      "1930.4\n",
      "1727.63\n",
      "1915.64\n",
      "1887.87\n",
      "1861.14\n",
      "1976.9\n",
      "1835.2\n",
      "1941.15\n",
      "1900.59\n",
      "1957.87\n",
      "1755.52\n",
      "2009.73\n",
      "1962.76\n",
      "1735.36\n",
      "1928.34\n",
      "1836.15\n",
      "1884.51\n",
      "1839.03\n",
      "1876.73\n",
      "1842.79\n",
      "1896.62\n",
      "1844.17\n",
      "1792.17\n",
      "1656.5\n",
      "1876.83\n",
      "1786.25\n",
      "1867.97\n",
      "1873.25\n",
      "1818.84\n",
      "1689.56\n",
      "1794.36\n",
      "1759.69\n",
      "1707.3\n",
      "1842.83\n",
      "1872.08\n",
      "1753.39\n",
      "1835.2\n",
      "1893.09\n",
      "2022.3\n",
      "1875.15\n",
      "1822.36\n",
      "1834.15\n",
      "1849.19\n",
      "1759.77\n",
      "1834.55\n",
      "1769.57\n",
      "1851.57\n",
      "1812.63\n",
      "1733.55\n",
      "1946.51\n",
      "1923.09\n",
      "1898.11\n",
      "1743.65\n",
      "1844.2\n",
      "1707.59\n",
      "1838.32\n",
      "1909.56\n",
      "1758.86\n",
      "1847.05\n",
      "1764.11\n",
      "1767.62\n",
      "1690.04\n",
      "1884.3\n",
      "1913.77\n",
      "1826.12\n",
      "1813.2\n",
      "1938.2\n",
      "1716.72\n",
      "1836.34\n",
      "1893.33\n",
      "1821.84\n",
      "1732.07\n",
      "1787.05\n",
      "1806.47\n",
      "1739.59\n",
      "1924.1\n",
      "1851.12\n",
      "1950.56\n",
      "1793.03\n",
      "1907.64\n",
      "1839.02\n",
      "1835.56\n",
      "1871.15\n",
      "1969.08\n",
      "1825.67\n",
      "1805.55\n",
      "1764.54\n",
      "1818.16\n",
      "1889.62\n",
      "1947.04\n",
      "1927.0\n",
      "1842.53\n",
      "2038.89\n",
      "1725.13\n",
      "1784.53\n",
      "1905.21\n",
      "1994.69\n",
      "1790.08\n",
      "1970.02\n",
      "1852.53\n",
      "1829.11\n",
      "1993.21\n",
      "1806.59\n",
      "1922.62\n",
      "1851.55\n",
      "1786.09\n",
      "1799.05\n",
      "1836.17\n",
      "1752.15\n",
      "1970.07\n",
      "1736.25\n",
      "1844.13\n",
      "1688.28\n",
      "1984.72\n",
      "1786.63\n",
      "1977.12\n",
      "1753.55\n",
      "1829.93\n",
      "1796.18\n",
      "1953.19\n",
      "1771.07\n",
      "1898.19\n",
      "1832.08\n",
      "1897.59\n",
      "1747.33\n",
      "1954.17\n",
      "1823.68\n",
      "1785.16\n",
      "1971.02\n",
      "1852.04\n",
      "1804.69\n",
      "1939.59\n",
      "1823.01\n",
      "1743.52\n",
      "1912.03\n",
      "1760.98\n",
      "1722.15\n",
      "1930.04\n",
      "1770.04\n",
      "1932.55\n",
      "1800.1\n",
      "1677.72\n",
      "1806.23\n",
      "1948.04\n",
      "1854.72\n",
      "1830.56\n",
      "1872.01\n",
      "1814.02\n",
      "1969.58\n",
      "1892.52\n",
      "1848.08\n",
      "1964.36\n",
      "1979.58\n",
      "1843.08\n",
      "1741.57\n",
      "1782.61\n",
      "1875.14\n",
      "1817.57\n",
      "1956.21\n",
      "1859.03\n",
      "1838.06\n",
      "1736.59\n",
      "1847.53\n",
      "1914.03\n",
      "1822.55\n",
      "1851.58\n",
      "1927.12\n",
      "1851.52\n",
      "1716.6\n",
      "1753.03\n",
      "1898.56\n",
      "1927.99\n",
      "1879.74\n",
      "1812.54\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-25cd708727e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH_WORD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH_WORD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_enc_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_output_multiplied\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_multiplied\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    Xin,Yin = get_random_reversed_dataset(Xdata,Ydata,batch_size)\n",
    "    Xin = np.array(Xin).T\n",
    "    Yin = np.array(Yin).T\n",
    "    feed_dict = {enc_input[t]: Xin[t] for t in range(MAX_LENGTH_WORD)}\n",
    "    feed_dict.update({dec_output[t]: Yin[t] for t in range(MAX_LENGTH_WORD)})\n",
    "    _, my_enc_state, my_outputs, my_output_multiplied,my_loss = sess.run([train_op,enc_state,outputs,output_multiplied,loss],feed_dict)\n",
    "    if i%250==1:\n",
    "        print(my_loss)\n",
    "# print(my_enc_state)\n",
    "# print(len(my_enc_state))\n",
    "# print(len(my_enc_state[0]))\n",
    "# print(my_enc_state[0])\n",
    "# print('expected above: 64 x 248')\n",
    "print(len(my_outputs))\n",
    "print(len(my_outputs[0]))\n",
    "# print(len(my_outputs[0][0]))\n",
    "# print(my_outputs[0][0])\n",
    "print(\"multiplied\")\n",
    "print(len(my_output_multiplied))\n",
    "print(len(my_output_multiplied[0]))\n",
    "print(len(my_output_multiplied[0][0]))\n",
    "\n",
    "# for index_now in range(10):\n",
    "\n",
    "#     \n",
    "#     _, l,the_state,ohin,sfsf,the_outputs,unstacked_sdfsf = sess.run([train_op,loss,state,one_hot_input,outputs,\n",
    "#                                                      output_multiplied,output_unstacked], feed_dict)\n",
    "#     if index_now%100==1:\n",
    "#         print(l)\n",
    "#         print(the_state)\n",
    "#         print(len(the_outputs))\n",
    "#         print(len(the_outputs[0]))\n",
    "#         print(len(the_outputs[0][0]))\n",
    "#         print(the_outputs[0][0])\n",
    "#         print(unstacked_sdfsf)\n",
    "#         print(the_state)\n",
    "#         print(len(the_state))\n",
    "#         print(len(the_state[0]))\n",
    "#         for character in ohin:\n",
    "#             print(character[0]) # get 0 from batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.unpack?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
